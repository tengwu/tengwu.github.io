<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>CS143 on me</title>
    <link>http://tengwu.quest/tags/cs143/</link>
    <description>Recent content in CS143 on me</description>
    <image>
      <title>me</title>
      <url>http://tengwu.quest/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://tengwu.quest/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 28 Mar 2023 18:32:00 +0800</lastBuildDate><atom:link href="http://tengwu.quest/tags/cs143/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>语法分析</title>
      <link>http://tengwu.quest/post/2023/03/parser/</link>
      <pubDate>Tue, 28 Mar 2023 18:32:00 +0800</pubDate>
      
      <guid>http://tengwu.quest/post/2023/03/parser/</guid>
      <description>语法分析简介 语法分析的任务 语法分析是编译器继词法分析之后的一个重要步骤,主要任务是将输入的源代码转换为语法分析树或者抽象语法树,以便后续的语义分析,中间代码生成和优化等处理.
具体来说,语法分析的任务包括以下几个方面:
识别输入的源代码中是否存在语法错误,即判断输入的源代码是否符合给定的文法规则.如果存在语法错误,语法分析器将报告相应的错误信息. 将输入的源代码转换为语法分析树或者抽象语法树.语法分析树是一个表示源代码语法结构的树形结构,每个节点代表源代码中的一个语法成分,如语句,表达式,运算符等.抽象语法树则是一种去除冗余信息后的语法树,只保留程序的语义信息,用于后续的代码生成和优化. 为每个节点附加语义信息,如数据类型,变量名,函数名等.这些信息将在后续的语义分析和代码生成中用到. 生成错误信息和警告信息,以便提示开发者对源代码进行改正. 强大的语法分析生成器 bison bison 是 flex 的亲密战友,它是一种强大的语法分析器生成器,可以根据用户提供的上下文无关文法生成相应的语法分析器.
bison 可以通过读取用户提供的语法规则,生成相应的语法分析器,从而将源代码转换为语法分析树或者抽象语法树,并对语法错误进行报告.
同时, bison 还提供了丰富的选项和功能,如语法冲突检查,语法错误处理,语法树的生成和遍历等,方便开发者进行灵活的配置和使用.
bison 的语法规则基于类似于 BNF 的范式,可以包含终结符和非终结符,以及相应的语义动作.它使用 LALR(1) 分析算法,能够高效地处理大规模的语法规则和输入流,同时还提供了一些高级特性,如词法和语法错误处理,优先级和关联性规则,语法树生成和遍历等.
使用 bison 手册1.8节提供了使用 bison 的一般步骤. 使用 bison 生成语法分析器的基本步骤与使用 flex 非常类似,具体步骤如下:
编写语法规则文件,将要分析的程序语言语法描述出来 使用 bison 编译语法规则文件,生成C文件 编译链接这些C文件成一个二进制程序 运行二进制程序,进行语法分析 下面以分析计算器的语法为例,说明一下这四个步骤:
编写语法规则文件（通常使用扩展名为 .y 的文件）,定义计算器的语法规则.以下是一个简单的例子:
%{ #include &amp;lt;stdio.h&amp;gt; %} %token NUMBER %left &amp;#39;+&amp;#39; &amp;#39;-&amp;#39; %left &amp;#39;*&amp;#39; &amp;#39;/&amp;#39; %precedence UMINUS %% expression: NUMBER | expression &amp;#39;+&amp;#39; expression | expression &amp;#39;-&amp;#39; expression | expression &amp;#39;*&amp;#39; expression | expression &amp;#39;/&amp;#39; expression | &amp;#39;-&amp;#39; expression %prec UMINUS ; %% int main() { yyparse(); return 0; } int yyerror(char const *msg) { fprintf(stderr, &amp;#34;Error: %s\n&amp;#34;, msg); return 0; } int yywrap() { return 1; } 其中,%{ 和 %} 之间的代码是在解析器中使用的C代码,%token 定义了词法分析器生成的符号类型,%left 和 %precedence 定义了运算符的优先级和结合性.</description>
    </item>
    
    <item>
      <title>词法分析</title>
      <link>http://tengwu.quest/post/2023/03/lexer/</link>
      <pubDate>Tue, 28 Mar 2023 15:27:00 +0800</pubDate>
      
      <guid>http://tengwu.quest/post/2023/03/lexer/</guid>
      <description>词法分析 简介 词法分析是编译原理中的一个重要步骤，它是将源代码中的字符序列（如程序、脚本等）分解成一系列的单词或词素（ Token ）的过程。 Token 是编程语言中的最小单元，它可以是关键字、标识符、运算符、常量或分隔符等。
词法分析器（ Lexer ）会读入源代码字符序列，扫描每个字符，并根据语法规则将字符序列分割成 Token 序列，然后将这些 Token 保存下来，交给下一步的语法分析器（ Parser ）进行分析和处理。
在词法分析的过程中，词法分析器通常会忽略空格、换行符等无关字符，只识别有效的 Token ，并为每个 Token 打上相应的类型标记。例如，对于C语言中的表达式 x\=y+3 ，词法分析器会识别出标识符 x 、 y 、 + 、 \= 和数字 3 ，并将它们分别打上相应的类型标记，以便后续的语法分析和代码生成。
词法分析算法 本节参考了&amp;quot;编译器设计 第二版&amp;quot;
主要包含从正则表达式构造 NFA ，从 NFA 到 DFA 的子集构造算法， NFA 模拟算法，最小化 DFA 的算法。
TODO
flex 使用的词法分析算法 flex 使用的词法分析算法是基于有限状态自动机 （Finite State Automaton，FSA） 的算法。它将用户定义的正则表达式转换成一个 DFA（Deterministic Finite Automaton，确定性有限状态自动机） ，然后通过扫描输入的字符序列，并根据 DFA 的状态转移规则逐个读入字符，最终得到 Token 序列。
flex 生成的词法分析器中包含一个状态转移表，该表包含了所有的状态和状态转移规则。每个状态对应一个状态号，每个字符对应一个字符类，状态转移表中的每个条目记录了当前状态、字符类和下一个状态。在扫描输入字符序列时，词法分析器会根据当前状态和读入的字符，查找状态转移表，找到下一个状态，并执行相应的动作，例如记录 Token 类型、值等。
flex 使用 FSA 算法的优点是速度快，生成的词法分析器代码比较紧凑，并且可以自动生成状态转移表，无需手动设计状态转移规则。缺点是在处理一些上下文相关的语言时，可能会出现识别错误的情况。</description>
    </item>
    
    <item>
      <title>CS143 PA1</title>
      <link>http://tengwu.quest/post/2023/03/cs143-pa1/</link>
      <pubDate>Tue, 28 Mar 2023 14:01:00 +0800</pubDate>
      
      <guid>http://tengwu.quest/post/2023/03/cs143-pa1/</guid>
      <description>Lexer 整体项目结构 宏观的目录结构如下：
$ tree cs143 -L 1 cs143 ├── assignments ├── bin ├── etc ├── examples ├── handouts ├── include ├── lib └── src cs143 目录包含了所有实验所需的文件，其中：
include 目录包含了实验所需头文件 assignments 目录包含了所有实验所需的源文件，实验过程中只需要修改 assignments 目录下的源文件就可以了 bin 目录包含了部分实验所需的二进制文件，比如 MIPS 模拟器 spim 等 etc 目录包含了一个名为 link-object 的二进制程序 examples 目录包含了一些 cool 语言写的代码示例 handouts 目录包含了实验手册 lib 目录包含了一些 java 的库文件，如果选择使用 C++ 来做实验，可以忽略这个目录 src 目录包含了实验中所有用到的源文件以及一些二进制文件，不太明白这个目录的意义，但是应该可以忽略 assigments 目录结构如下所示：
$ tree assigments assigments ├── PA1 │ ├── Makefile │ ├── README │ ├── atoi.</description>
    </item>
    
  </channel>
</rss>
